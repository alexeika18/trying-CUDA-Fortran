module dimensions_m

  implicit none

  integer, parameter :: TILE_DIM = 32
  integer, parameter :: BLOCK_ROWS = 8
  integer, parameter :: NUM_REPS = 100
  integer, parameter :: nx = 1024, ny = 1024
  integer, parameter :: mem_size = nx*ny*4

end module dimensions_m



module kernels_m

  use dimensions_m
  implicit none

contains

  ! naive multiplication
  !
  ! simplest transpose - doesn't use shared memory
  ! reads from global memory are coalesced but not writes

  attributes(global) &
       subroutine multiplyNaive(odata, idata1, idata2)

    real, intent(out) :: odata(ny,nx)
    real, intent(in) :: idata1(nx,ny), idata2(nx,ny)

    integer :: x, y, j, n

    x = (blockIdx%x-1) * TILE_DIM + threadIdx%x
    y = (blockIdx%y-1) * TILE_DIM + threadIdx%y

    do j = 0, TILE_DIM-1, BLOCK_ROWS
        do n = 1, ny
            odata(x, y+j) = idata1(x,n) + idata2(y+j,n)
        end do
    end do
  end subroutine multiplyNaive


end module kernels_m



program multiplication

  use cutensor
  use cudafor
  use kernels_m
  use dimensions_m

  implicit none

  type (dim3) :: grid, tBlock
  type (cudaEvent) :: startEvent, stopEvent
  type (cudaDeviceProp) :: prop
  real :: time

  real :: in1_h(nx,ny), in2_h(nx,ny), copy_h(nx,ny), mul_h(ny,nx)
  real :: gold(ny,nx)
  real, device :: in1_d(nx,ny), in2_d(nx,ny), copy_d(nx,ny), mul_d(ny,nx)

  integer :: i, j, istat

  ! check parameters and calculate execution configuration

  if (mod(nx, TILE_DIM) /= 0 &
       .or. mod(ny, TILE_DIM) /= 0) then
     write(*,*) 'nx and ny must be a multiple of TILE_DIM'
     stop
  end if

  if (mod(TILE_DIM, BLOCK_ROWS) /= 0) then
     write(*,*) 'TILE_DIM must be a multiple of BLOCK_ROWS'
     stop
  end if

  grid = dim3(nx/TILE_DIM, ny/TILE_DIM, 1)
  tBlock = dim3(TILE_DIM, BLOCK_ROWS, 1)

  ! write parameters

  i = cudaGetDeviceProperties(prop, 0)
  write(*,"(/,'Device Name: ',a)") trim(prop%name)
  write(*,"('Compute Capability: ',i0,'.',i0)") &
       prop%major, prop%minor


  write(*,*)
  write(*,"('Matrix size:', i5, i5, ',  Block size:', &
       i3, i3, ',  Tile size:', i3, i3)") &
       nx, ny, TILE_DIM, BLOCK_ROWS, TILE_DIM, TILE_DIM

  write(*,"('grid:', i4,i4,i4, ',   tBlock:', i4,i4,i4)") &
       grid%x, grid%y, grid%z, tBlock%x, tBlock%y, tBlock%z

  ! initialize data

  ! host

  do j = 1, ny
     do i = 1, nx
        in1_h(i,j) = i+(j-1)*nx
        in2_h(i,j) = i+(j-1)*nx
     enddo
  enddo

  gold = matmul(in1_h, in2_h)

  ! device

  in1_d = in1_h
  in2_d = in2_h
  mul_d = -1.0
  copy_d = -1.0

  ! events for timing

  istat = cudaEventCreate(startEvent)
  istat = cudaEventCreate(stopEvent)

  ! ------------
  ! time kernels
  ! ------------

  write(*,'(/,a25,a25)') 'Routine', 'Bandwidth (GB/s)'

  ! --------------
  ! multiplyNaive
  ! --------------

  write(*,'(a25)', advance='NO') 'naive multiplication'

  mul_d = -1.0
  ! warmup
  call multiplyNaive<<<grid, tBlock>>>(mul_d, in1_d, in2_d)

  istat = cudaEventRecord(startEvent, 0)
  do i=1, NUM_REPS
     call multiplyNaive<<<grid, tBlock>>>(mul_d, in1_d, in2_d)
  end do
  istat = cudaEventRecord(stopEvent, 0)
  istat = cudaEventSynchronize(stopEvent)
  istat = cudaEventElapsedTime(time, startEvent, stopEvent)

  mul_h = mul_d
  call postprocess(gold, mul_h, time)

contains

  subroutine postprocess(ref, res, t)
    real, intent(in) :: ref(:,:), res(:,:), t
    if (all(res == ref)) then
       write(*,'(f20.2)') 2.0*mem_size*1.0e-6/(t/NUM_REPS)
    else
       write(*,'(a20)') '*** Failed ***'
    end if
  end subroutine postprocess

end program multiplication
